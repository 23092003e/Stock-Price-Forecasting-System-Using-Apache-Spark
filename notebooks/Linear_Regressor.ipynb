{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import datetime\n",
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, lit, date_add, explode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+--------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+----------+\n",
      "|      Date|      Open|      High|       Low|     Close|  Volume|       Price_Range|       Daily_Change|             MA_10|             MA_50|               RSI|          Upper_BB|          Lower_BB|          Stoch_Osc|    Target|\n",
      "+----------+----------+----------+----------+----------+--------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+----------+\n",
      "|2018-02-07|266.579987|272.450012|264.329987|264.559998| 8981500| 8.120024999999998|-2.0199890000000096| 261.5133313333333| 261.5133313333333|  90.8082236708388| 274.1299184650964|248.89674420157024|  71.96474097564031|250.100006|\n",
      "|2018-02-08|267.079987|267.619995|     250.0|250.100006| 9306700|17.619995000000017| -16.97998100000001|258.65999999999997|258.65999999999997| 42.31907524671068| 274.0347469052368| 243.2852530947632|-13.719121567657453|249.470001|\n",
      "|2018-02-09|253.850006|255.800003|236.110001|249.470001|16906900|19.690001999999993| -4.380005000000011|256.82200019999993|256.82200019999993| 41.35692356039187| 272.4697475489338| 241.1742528510661| 2.2117851277440064|257.950012|\n",
      "|2018-02-12|252.139999|259.149994|     249.0|257.950012| 8534900|10.149993999999992|  5.810013000000026|257.01000216666665|257.01000216666665|55.098114488313186|271.03604478118007|242.98395955215324|  55.94332331375277|258.269989|\n",
      "|2018-02-13|257.290009|261.410004|254.699997|258.269989| 6855200| 6.710007000000019| 0.9799800000000118|257.19000028571423|257.19000028571423| 55.49163880991051| 270.0293437486885|244.35065682273995|  57.64767495159775|     266.0|\n",
      "+----------+----------+----------+----------+----------+--------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Netflix Stock Price Forecasting\") \\\n",
    "    .getOrCreate()\n",
    "data_url = r\"C:\\Users\\ADMIN\\Desktop\\Stock-Price-Forecasting-System-Using-Apache-Spark\\data\\processed\\data.csv\"    \n",
    "# Load the data\n",
    "df = spark.read.csv(data_url, header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1006, Columns: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rows: {df.count()}, Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = [\"Open\", \"High\", \"Low\", \"Volume\", \"Price_Range\", \"Daily_Change\", \n",
    "                \"MA_10\", \"MA_50\", \"RSI\", \"Upper_BB\", \"Lower_BB\", \"Stoch_Osc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data chronologically (80% train, 20% test)\n",
    "total_rows = df.count()\n",
    "train_rows = int(total_rows * 0.8)\n",
    "train_df = df.orderBy(\"Date\").limit(train_rows)\n",
    "test_df = df.orderBy(\"Date\").exceptAll(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+----------+----------+--------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+----------+\n",
      "|               Date|      Open|      High|       Low|     Close|  Volume|       Price_Range|       Daily_Change|             MA_10|             MA_50|               RSI|          Upper_BB|          Lower_BB|          Stoch_Osc|    Target|\n",
      "+-------------------+----------+----------+----------+----------+--------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+----------+\n",
      "|2018-02-07 00:00:00|266.579987|272.450012|264.329987|264.559998| 8981500| 8.120024999999998|-2.0199890000000096| 261.5133313333333| 261.5133313333333|  90.8082236708388| 274.1299184650964|248.89674420157024|  71.96474097564031|250.100006|\n",
      "|2018-02-08 00:00:00|267.079987|267.619995|     250.0|250.100006| 9306700|17.619995000000017| -16.97998100000001|258.65999999999997|258.65999999999997| 42.31907524671068| 274.0347469052368| 243.2852530947632|-13.719121567657453|249.470001|\n",
      "|2018-02-09 00:00:00|253.850006|255.800003|236.110001|249.470001|16906900|19.690001999999993| -4.380005000000011|256.82200019999993|256.82200019999993| 41.35692356039187| 272.4697475489338| 241.1742528510661| 2.2117851277440064|257.950012|\n",
      "|2018-02-12 00:00:00|252.139999|259.149994|     249.0|257.950012| 8534900|10.149993999999992|  5.810013000000026|257.01000216666665|257.01000216666665|55.098114488313186|271.03604478118007|242.98395955215324|  55.94332331375277|258.269989|\n",
      "|2018-02-13 00:00:00|257.290009|261.410004|254.699997|258.269989| 6855200| 6.710007000000019| 0.9799800000000118|257.19000028571423|257.19000028571423| 55.49163880991051| 270.0293437486885|244.35065682273995|  57.64767495159775|     266.0|\n",
      "+-------------------+----------+----------+----------+----------+--------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Date\", col(\"Date\").cast(\"timestamp\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set row count: 804\n",
      "Testing set row count: 202\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set row count: {train_df.count()}\")\n",
    "print(f\"Testing set row count: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+\n",
      "|      Date|     scaled_features|     Close|\n",
      "+----------+--------------------+----------+\n",
      "|2018-02-07|[0.09370782339566...|264.559998|\n",
      "|2018-02-08|[0.09514242007289...|250.100006|\n",
      "|2018-02-09|[0.05718304650801...|249.470001|\n",
      "|2018-02-12|[0.05227670578752...|257.950012|\n",
      "|2018-02-13|[0.06705308025494...|258.269989|\n",
      "+----------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create pipeline to process data\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "assembler = VectorAssembler(inputCols=features_col, outputCol='features')\n",
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaled_features')\n",
    "pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "# transform data \n",
    "transformer = pipeline.fit(train_df)\n",
    "train_set = transformer.transform(train_df).select(\"Date\",'scaled_features', 'Close')\n",
    "test_set = transformer.transform(test_df).select('Date','scaled_features', 'Close')\n",
    "\n",
    "train_set.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "linear_regressor = LinearRegression(\n",
    "    featuresCol='scaled_features', \n",
    "    labelCol='Close')\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol='Close', \n",
    "    predictionCol='prediction', \n",
    "    metricName='rmse')\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(linear_regressor.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(linear_regressor.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(linear_regressor.maxIter, [10, 100, 200]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Params:\n",
      "  Regularization Param (regParam): 0.01\n",
      "  ElasticNet Param (elasticNetParam): 0.0\n",
      "  Maximum Iterations (maxIter): 10\n"
     ]
    }
   ],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=linear_regressor,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds = 3\n",
    ")\n",
    "\n",
    "# Fit the cross-validator to find the best moel\n",
    "cv_model = crossval.fit(train_set)\n",
    "\n",
    "# Get the best model from cross validation\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "print(\"Best Model Params:\")\n",
    "print(\"  Regularization Param (regParam):\", best_model.getRegParam())\n",
    "print(\"  ElasticNet Param (elasticNetParam):\", best_model.getElasticNetParam())\n",
    "print(\"  Maximum Iterations (maxIter):\", best_model.getMaxIter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.12652211632295657\n",
      "RMSE: 0.35569947472966074\n",
      "MAE: 0.26686455528768627\n",
      "R2 Score: 0.9999738877856017\n"
     ]
    }
   ],
   "source": [
    "prediction_test = best_model.transform(test_set)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol='Close', \n",
    "    predictionCol='prediction', \n",
    "    metricName='rmse')\n",
    "\n",
    "# Calculate metrics\n",
    "mse = evaluator.evaluate(prediction_test, {evaluator.metricName: \"mse\"})\n",
    "rmse = evaluator.evaluate(prediction_test, {evaluator.metricName: \"rmse\"})\n",
    "mae = evaluator.evaluate(prediction_test, {evaluator.metricName: \"mae\"})\n",
    "r2 = evaluator.evaluate(prediction_test, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2 Score:\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+-----------------+\n",
      "|      Date|     scaled_features|     Close|       prediction|\n",
      "+----------+--------------------+----------+-----------------+\n",
      "|2021-07-21|[0.83840701019224...|513.630005|513.4410903003127|\n",
      "|2021-08-05|[0.81258427000206...|524.890015|524.7955351594778|\n",
      "|2021-10-21|[1.13324534798888...|653.159973| 653.110173022169|\n",
      "|2021-06-23|[0.78776576470111...| 512.73999|513.0245687530501|\n",
      "|2021-08-18|[0.82081884058341...|521.869995|522.1324075992263|\n",
      "+----------+--------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = test_set.join(prediction_test.select(\"Date\",\"prediction\"), on=\"Date\", how=\"left\")\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ../model/linear_regressor_sklearn.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.coef_ = best_model.coefficients.toArray()\n",
    "sklearn_model.intercept_ = best_model.intercept\n",
    "\n",
    "model_path = \"../model/linear_regressor_sklearn.pkl\"\n",
    "joblib.dump(sklearn_model, model_path)\n",
    "\n",
    "print(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
